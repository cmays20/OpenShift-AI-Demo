{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "15acb3be8d1df303"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "%pip install kaggle kagglehub plotly numpy pandas pillow matplotlib ipywidgets scipy",
   "id": "66f978d6fca5923c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"airbusgeo/airbus-aircrafts-sample-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ],
   "id": "4a1fad27b48dca2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import PIL\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ],
   "id": "ad97387b16092ec7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip install ultralytics\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "!yolo checks"
   ],
   "id": "f5cde96ee8ee1e82"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip install albumentations==1.0.3\n",
    "display.clear_output()\n",
    "!pip show albumentations"
   ],
   "id": "6d5b743ab4e721d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "DATA_DIR = Path(path)\n",
    "img_list = list(DATA_DIR.glob('images/*.jpg'))\n",
    "pickone = random.choice(img_list)\n",
    "display.Image(pickone)"
   ],
   "id": "8bb08d54755427c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(f\"Found {len(img_list)} images files in {DATA_DIR}\")\n",
    "\n",
    "img = PIL.Image.open(pickone)\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH = img.size\n",
    "num_channels = len(img.mode)\n",
    "print(\"Image size: {}\".format((IMAGE_HEIGHT, IMAGE_WIDTH)))\n",
    "print(\"Num channels: {}\".format(num_channels))"
   ],
   "id": "224f180385f4f78f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.read_csv(DATA_DIR / 'annotations.csv')\n",
    "# convert a string record into a valid python object\n",
    "def f(x):\n",
    "    return ast.literal_eval(x.rstrip('\\r\\n'))\n",
    "\n",
    "df = pd.read_csv(DATA_DIR / \"annotations.csv\",\n",
    "                converters={'geometry': f})\n",
    "df.head(10)"
   ],
   "id": "fbbb1e9bc92dd865"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def getBounds(geometry):\n",
    "    try:\n",
    "        arr = np.array(geometry).T\n",
    "        xmin = np.min(arr[0])\n",
    "        ymin = np.min(arr[1])\n",
    "        xmax = np.max(arr[0])\n",
    "        ymax = np.max(arr[1])\n",
    "        return (xmin, ymin, xmax, ymax)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def getWidth(bounds):\n",
    "    try:\n",
    "        (xmin, ymin, xmax, ymax) = bounds\n",
    "        return np.abs(xmax - xmin)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def getHeight(bounds):\n",
    "    try:\n",
    "        (xmin, ymin, xmax, ymax) = bounds\n",
    "        return np.abs(ymax - ymin)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Create bounds, width and height\n",
    "df.loc[:,'bounds'] = df.loc[:,'geometry'].apply(getBounds)\n",
    "df.loc[:,'width'] = df.loc[:,'bounds'].apply(getWidth)\n",
    "df.loc[:,'height'] = df.loc[:,'bounds'].apply(getHeight)\n",
    "df.head(10)"
   ],
   "id": "9b8bbd54107e55db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# create a list of images used for validation\n",
    "fold = 1\n",
    "num_fold = 5\n",
    "index = df['image_id'].unique()\n",
    "val_indexes = index[len(index)*fold//num_fold:len(index)*(fold+1)//num_fold]\n",
    "print(val_indexes)"
   ],
   "id": "56542104f4d24065"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import tqdm.notebook\n",
    "\n",
    "# Create 512x512 tiles with 64 pix overlap in /kaggle/working\n",
    "TILE_WIDTH = 512\n",
    "TILE_HEIGHT = 512\n",
    "TILE_OVERLAP = 64\n",
    "TRUNCATED_PERCENT = 0.3\n",
    "_overwriteFiles = True\n",
    "\n",
    "TILES_DIR = {'train': Path('kaggle/working/train/images/'),\n",
    "             'val': Path('kaggle/working/val/images/')}\n",
    "for _, folder in TILES_DIR.items():\n",
    "    if not os.path.isdir(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "LABELS_DIR = {'train': Path('kaggle/working/train/labels/'),\n",
    "              'val': Path('kaggle/working/val/labels/')}\n",
    "for _, folder in LABELS_DIR.items():\n",
    "    if not os.path.isdir(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "# Save one line in .txt file for each tag found inside the tile\n",
    "def tag_is_inside_tile(bounds, x_start, y_start, width, height, truncated_percent):\n",
    "    x_min, y_min, x_max, y_max = bounds\n",
    "    x_min, y_min, x_max, y_max = x_min - x_start, y_min - y_start, x_max - x_start, y_max - y_start\n",
    "\n",
    "    if (x_min > width) or (x_max < 0.0) or (y_min > height) or (y_max < 0.0):\n",
    "        return None\n",
    "\n",
    "    x_max_trunc = min(x_max, width)\n",
    "    x_min_trunc = max(x_min, 0)\n",
    "    if (x_max_trunc - x_min_trunc) / (x_max - x_min) < truncated_percent:\n",
    "        return None\n",
    "\n",
    "    y_max_trunc = min(y_max, width)\n",
    "    y_min_trunc = max(y_min, 0)\n",
    "    if (y_max_trunc - y_min_trunc) / (y_max - y_min) < truncated_percent:\n",
    "        return None\n",
    "\n",
    "    x_center = (x_min_trunc + x_max_trunc) / 2.0 / width\n",
    "    y_center = (y_min_trunc + y_max_trunc) / 2.0 / height\n",
    "    x_extend = (x_max_trunc - x_min_trunc) / width\n",
    "    y_extend = (y_max_trunc - y_min_trunc) / height\n",
    "\n",
    "    return (0, x_center, y_center, x_extend, y_extend)\n",
    "\n",
    "for img_path in tqdm.notebook.tqdm(img_list):\n",
    "    # Open image and related data\n",
    "    pil_img = PIL.Image.open(img_path, mode='r')\n",
    "    np_img = np.array(pil_img, dtype=np.uint8)\n",
    "\n",
    "    # Get annotations for image\n",
    "    img_labels = df[df[\"image_id\"] == img_path.name]\n",
    "    #print(img_labels)\n",
    "\n",
    "    # Count number of sections to make\n",
    "    X_TILES = (IMAGE_WIDTH + TILE_WIDTH + TILE_OVERLAP - 1) // TILE_WIDTH\n",
    "    Y_TILES = (IMAGE_HEIGHT + TILE_HEIGHT + TILE_OVERLAP - 1) // TILE_HEIGHT\n",
    "\n",
    "    # Cut each tile\n",
    "    for x in range(X_TILES):\n",
    "        for y in range(Y_TILES):\n",
    "\n",
    "            x_end = min((x + 1) * TILE_WIDTH - TILE_OVERLAP * (x != 0), IMAGE_WIDTH)\n",
    "            x_start = x_end - TILE_WIDTH\n",
    "            y_end = min((y + 1) * TILE_HEIGHT - TILE_OVERLAP * (y != 0), IMAGE_HEIGHT)\n",
    "            y_start = y_end - TILE_HEIGHT\n",
    "            #print(x_start, y_start)\n",
    "\n",
    "            folder = 'val' if img_path.name in val_indexes else 'train'\n",
    "            save_tile_path = TILES_DIR[folder].joinpath(img_path.stem + \"_\" + str(x_start) + \"_\" + str(y_start) + \".jpg\")\n",
    "            save_label_path = LABELS_DIR[folder].joinpath(img_path.stem + \"_\" + str(x_start) + \"_\" + str(y_start) + \".txt\")\n",
    "\n",
    "            # Save if file doesn't exit\n",
    "            if _overwriteFiles or not os.path.isfile(save_tile_path):\n",
    "                cut_tile = np.zeros(shape=(TILE_WIDTH, TILE_HEIGHT, 3), dtype=np.uint8)\n",
    "                cut_tile[0:TILE_HEIGHT, 0:TILE_WIDTH, :] = np_img[y_start:y_end, x_start:x_end, :]\n",
    "                cut_tile_img = PIL.Image.fromarray(cut_tile)\n",
    "                cut_tile_img.save(save_tile_path)\n",
    "\n",
    "            found_tags = [\n",
    "                tag_is_inside_tile(bounds, x_start, y_start, TILE_WIDTH, TILE_HEIGHT, TRUNCATED_PERCENT)\n",
    "                for i, bounds in enumerate(img_labels['bounds'])]\n",
    "            found_tags = [el for el in found_tags if el is not None]\n",
    "\n",
    "            # save labels\n",
    "            with open(save_label_path, 'w+') as f:\n",
    "                for tags in found_tags:\n",
    "                    f.write(' '.join(str(x) for x in tags) + '\\n')"
   ],
   "id": "8a1fd66c525e8383"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "CONFIG = \"\"\"\n",
    "# train and val datasets (image directory or *.txt file with image paths)\n",
    "train: train/\n",
    "val: val/\n",
    "\n",
    "# number of classes\n",
    "nc: 1\n",
    "\n",
    "# class names\n",
    "names: ['Aircraft']\n",
    "\"\"\"\n",
    "\n",
    "with open(\"kaggle/working/data.yaml\", \"w\") as f:\n",
    "    f.write(CONFIG)"
   ],
   "id": "a3cafb5a534373a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "HOME = \"kaggle/working/\"\n",
    "!yolo task=detect mode=train model=yolov11s.pt data={HOME}/data.yaml epochs=10 imgsz=512 augment=True auto_augment=True"
   ],
   "id": "6ed126ef909c2baa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_path = 'runs/detect/train'\n",
    "\n",
    "display.Image(filename=train_path + '/BoxF1_curve.png', width=600)"
   ],
   "id": "9d70b2d7102430b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(train_path + \"/results.csv\")\n",
    "fig = px.line(df, x='epoch', y='metrics/mAP50(B)', title='mAP50')\n",
    "fig.show()"
   ],
   "id": "dfcfbe748f134a63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "display.Image(filename=train_path + '/val_batch0_pred.jpg', width=1000)",
   "id": "faac2991a0cc72ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!yolo task=detect mode=val model={train_path}/weights/best.pt data={HOME}/data.yaml",
   "id": "b3d976fbf3f53d0e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Load your trained model\n",
    "model_path = train_path + \"/weights/best.pt\"  # Update this path if needed\n",
    "model = YOLO(model_path)\n",
    "\n",
    "print(f\"(Model loaded)\")"
   ],
   "id": "5b4a23aa61e1e23f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Path to your test images folder\n",
    "test_images_path = path + \"/extras\"  # Change this to your test images folder\n",
    "\n",
    "# Get all images in the test folder\n",
    "test_images = [str(p) for p in Path(test_images_path).glob(\"*.jpg\")]\n",
    "print(f\"Found {len(test_images)} test images\")"
   ],
   "id": "cd5df8603cf89f3e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Set confidence threshold\n",
    "conf_threshold = 0.25\n",
    "\n",
    "# Run inference on all test images\n",
    "results = model(test_images, conf=conf_threshold)\n",
    "\n",
    "print(f\"Inference completed for {len(results)} images\")"
   ],
   "id": "21a53751eed5b80a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Function to visualize an image with bounding boxes\n",
    "def visualize_with_boxes(image_path, result, save_path=None):\n",
    "    \"\"\"\n",
    "    Visualize image with predicted bounding boxes\n",
    "\n",
    "    Args:\n",
    "        image_path: Path to the image\n",
    "        result: YOLO result object for the image\n",
    "        save_path: Path to save the visualization (optional)\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    img = Image.open(image_path)\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(1, figsize=(12, 9))\n",
    "    ax.imshow(img_np)\n",
    "\n",
    "    # Get the predictions (boxes, scores, and class indices)\n",
    "    boxes = result.boxes.xyxy.cpu().numpy()\n",
    "    scores = result.boxes.conf.cpu().numpy()\n",
    "    class_ids = result.boxes.cls.cpu().numpy().astype(int)\n",
    "    class_names = [result.names[class_id] for class_id in class_ids]\n",
    "\n",
    "    # Loop through the detections and add bounding boxes\n",
    "    for box, score, class_name in zip(boxes, scores, class_names):\n",
    "        x1, y1, x2, y2 = box\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "\n",
    "        # Create a rectangle patch\n",
    "        rect = patches.Rectangle((x1, y1), width, height, linewidth=2, edgecolor='r', facecolor='none')\n",
    "\n",
    "        # Add the patch to the Axes\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Add label with class name and confidence score\n",
    "        plt.text(x1, y1-10, f\"{class_name}: {score:.2f}\",\n",
    "                 bbox=dict(facecolor='red', alpha=0.5),\n",
    "                 color='white', fontsize=12)\n",
    "\n",
    "    # Set title with the filename\n",
    "    plt.title(f\"Predictions for {os.path.basename(image_path)}\")\n",
    "\n",
    "    # Remove axis ticks\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Save if a save path is provided\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "        print(f\"Saved visualization to {save_path}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ],
   "id": "de4b975e52a7f418"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create output directory for visualizations\n",
    "output_dir = \"visualization_results\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ],
   "id": "f781792901b9855e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Visualize each result\n",
    "for i, (img_path, result) in enumerate(zip(test_images, results)):\n",
    "    print(f\"Visualizing image {i+1}/{len(results)}: {os.path.basename(img_path)}\")\n",
    "\n",
    "    # Path to save the visualization\n",
    "    save_path = os.path.join(output_dir, f\"viz_{os.path.basename(img_path)}\")\n",
    "\n",
    "    # Visualize and save\n",
    "    visualize_with_boxes(img_path, result, save_path)"
   ],
   "id": "d962a77dbcd39786"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
